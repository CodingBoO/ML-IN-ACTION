# 支持向量机(Support Vector Machines)
## 一、 特点
> 优点：

泛化错误率低，计算开销不大，结果易解释
> 缺点：

对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二分类器问题
> 适用数据类型：

数值型和标称型数据
## 二、超平面
将数据集分割开来的直线称为分割超平面(separating hyperplane)。当数据点都在二维平面上，此时分割超平面就是一条直线。如果数据集是三维的，此时分割超平面就是一个平面。

显而易见，更高维的情况可以一次类推。如果数据集是1024维的，那么就需要一个1023维的某某对象来对数据集进行分割。

这个1023维的某对象叫什么？N-1维呢？该对象被称为超平面（hyperplane），也就是分类的决策边界。
## 三、分类器构建
1. 如果数据点距离决策边界越远，那么其最后的预测结果也就越可信。
2. 我们希望找到距离分隔超平面最近的点，确保他们离分隔面的距离尽可能远。这里点到分隔面的距离被称为间隔（margin）
3. SVM分类器是要找到最大的数据集间隔
4. 支持向量就是离分隔超平面最近的那些点，接下来要试着最大化支持向量到分隔面的距离，需要找到此问题的优化求解方法
## 四、范数

要更好的理解范数，就要从函数、几何与矩阵的角度去理解，我尽量讲的通俗一些。

我们都知道，函数与几何图形往往是有对应的关系，这个很好想象，特别是在三维以下的空间内，函数是几何图像的数学概括，而几何图像是函数的高度形象化，比如一个函数对应几何空间上若干点组成的图形。但当函数与几何超出三维空间时，就难以获得较好的想象，于是就有了映射的概念，映射表达的就是一个集合通过某种关系转为另外一个集合。

通常数学书是先说映射，然后再讨论函数，这是因为函数是映射的一个特例。为了更好的在数学上表达这种映射关系，（这里特指线性关系）于是就引进了矩阵。这里的矩阵就是表征上述空间映射的线性关系。而通过向量来表示上述映射中所说的这个集合，而我们通常所说的基，就是这个集合的最一般关系。

于是，我们可以这样理解，一个集合（向量），通过一种映射关系（矩阵），得到另外一个几何（另外一个向量）。那么向量的范数，就是表示这个原有集合的大小。而矩阵的范数，就是表示这个变化过程的大小的一个度量。那么说到具体几几范数，其不过是定义不同，一个矩阵范数往往由一个向量范数引出，我们称之为算子范数，其物理意义都如我上述所述。以上符合知乎回答问题的方式。

接下来用百度回答方式：

0范数，向量中非零元素的个数。

1范数，为绝对值之和。

2范数，就是通常意义上的模。

以下分别列举常用的向量范数和矩阵范数的定义。
* 向量范数

### 1-范数：
$||x||$
![Markdown](http://i2.bvimg.com/602813/b149879396a97d3b.png)
即向量元素绝对值之和，matlab调用函数norm(x, 1) 。
 
### 2-范数：
![Markdown](http://i2.bvimg.com/602813/cceccd43c6c6daba.png)Euclid范数（欧几里得范数，常用计算向量长度），即向量元素绝对值的平方和再开方，matlab调用函数norm(x, 2)。
### 正无穷-范数：
![Markdown](http://i2.bvimg.com/602813/355b5b51eaaefdfd.png)
即所有向量元素绝对值中的最大值，matlab调用函数norm(x, inf)。
### 负无穷范数：
![Markdown](http://i4.bvimg.com/602813/442447294da91079.png)
即所有向量元素绝对值中的最小值，matlab调用函数norm(x, -inf)。
### p-范数：
![Markdown](http://i4.bvimg.com/602813/986d936d4e103fa2.png)
即向量元素绝对值的p次方和的1/p次幂，matlab调用函数norm(x, p)。
* 矩阵范数
### 1-范数：
![Markdown](http://i2.bvimg.com/602813/9df5316108bedb7d.png) 列和范数，即所有矩阵列向量绝对值之和的最大值，matlab调用函数norm(A, 1)。
### 2-范数：
![Markdown](http://i2.bvimg.com/602813/e63bbc7fbff54cb1.png)
为（A的转置A）的最大特征值。
### 谱范数，
即A'A矩阵的最大特征值的开平方。matlab调用函数norm(x, 2)。
### 无穷-范数：
![Markdown](http://i4.bvimg.com/602813/3536b84ef5c5049b.png)
行和范数，即所有矩阵行向量绝对值之和的最大值，matlab调用函数norm(A, inf)。
### F-范数：
![Markdown](http://i4.bvimg.com/602813/09ec005dec5ae6ac.png)Frobenius范数，即矩阵元素绝对值的平方和再开平方，matlab调用函数norm(A, ’fro‘)。
### 核范数：
是A的奇异值。即奇异值之和。
## 五、SMO优化算法
1. 介绍
SMO表示序列最小优化（Sequential Minimal Optimization）。

Platt的SMO算法是将大优化问题分解为多个小优化问题来求解的。这些小优化问题往往很容易求解，并且对他们进行顺序求解的结果与将他们作为整体来求解的结果是完全一致的。并且，SMO算法求解的时间短很多。

SMO的目标是求出一系列alpha和b，一旦求出了这些alpha，就很容易计算出权重向量w并得到分隔超平面。
2. 原理
每次循环中选择两个alpha进行优化处理。一旦找到一对合适的alpha，那么就增大其中一个同时减少另一个。

这里所谓的合适就是指两个alpha必须要符合一定的条件，

条件之一就是这两个alpha必须要在间隔边界外，而

弟二个条件就是这两个alpha还没用进行过区间优化或者不在边界上
## 六、 核函数
1. 从某个特征空间到另一个特征空间的映射是通过核函数来实现的。可以把核函数想象成一个包装器或者是接口，他能把数据从某个很难处理的形式转换成为另一个比较容易处理的形式
2. 其实是一种距离计算的方法
3. 向量的内积指的是两个向量相乘，之后得到单个标量或者数值。将内积替换成核函数的方式被称为核技巧（kernel trick）或者核变电（kernel substation）
### 径向基核函数 --- 一种流行的核函数
1. 径向基函数是一个采用**向量**作为**自变量**的函数，能够基于向量距离运算输出一个标量。这个距离可以是从$<0,0>$向量或其他向量开始计算的距离。
2. 径向基函数的高斯版本，其具体公式如下：
$$k(x, y) = exp\lgroup\frac{-||x-y||^2}{2\sigma^2}\rgroup$$
其中$\sigma$是用户定义的用于确定到达率（reach）或者说函数值跌落到0的速度参数
3. 高斯核函数将数据从其特征空间映射到更高维的空间，具体来说这里是映射到一个无穷维的空间